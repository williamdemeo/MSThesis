the distribution of interest. This is the purpose of bounding convergence rates for Markov chains.

Often the Markov chains encountered in this context satisfy a condition known in the
physics literature as detailed balance. Probabilists call chains with this property reversible. This
simply means that the chain has the same probability law whether time moves forward or backward.‘
In this paper, we consider the rate at which such chains converge to a stationary distribution.2

There are a number of different methods in common use for bounding convergence rates of
Markov chains, and a good review of these methods with many references can be found in  More
recently developed methods, employing logarithmic Sobolev inequalities, are reviewed in  Most
of the bounds in common use involve the sub—dominant eigenvalue of the Markov chain’s transition
probability matrix, and thus require good approximations to such eigenvalues. In many applications,
however, the transition probability matrix is so large that it becomes impossible to store even a
single vector of the matrix in conventional computer memory. These so called out-of-core problems
are not amenable to traditional eigenvalue algorithms3 without modiﬁcation. This paper develops
such a modiﬁcation for the Markov chain eigenvalue problem. In particular it develops a method
for approximating the ﬁrst few eigenvalues of a transition probability matrix when we know the
general structure of the underlying Markov chain. The method does not require storage of large
matrices or vectors. Instead we need only simulate the Markov chain, and conduct a statistical
analysis of the simulation.

Here is a look at what follows. Section 2.1 contains a review of the relevant Markov chain
theory. Readers conversant in the asymptotic theory of Markov chains might wish to at least skim

Section 2.1, if only to become familiar with our notation. Section 2.2 describes functions on the state

 

‘This is not a precise deﬁnition. In particular the chain must have started from its stationary distribution. Full
rigor is postponed until Section 2.1.

’This and other italicized terms are defined in Section 2.1.

3By “traditional eigenvalue algorithms” we refer to those found, for example, in Golub and Van Loan[5]. See also
the book by Demmel [1] for a more recent discussion.

