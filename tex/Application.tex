
\chapter{An Application: convergence to Gibbs measure on the Ising lattice}
%Chapter 5
\label{cha:an-appl-conv}

5.1 Physical Motivation

Before considering the details of the Metropolis algorithm, it helps to understand the
setting in which it was developed. To do so we consider an typical example, the Ising model.
Consider a model of a system consisting of 71 “sites”, each site taking values in {-1, +1}. It might
help to imagine these sites as equally spaced points on a line or a circle, though we are not restricted
to such cases. Then our state space 5' consists of all possible n—dimensional permutations of -1’s
and +1’s. We reprent this as S’ = {-1, +1}", and note that |S| = 2". We can think ofeach site as
a node existing in one of two possible positions, say “on" or “off”. Each state 1' E S is represented
by a unique permutation a.- of —1’s and +1’s. Let a,-(k) = :|:l denote the position (on or off) of
the kth node when the system is in state 1'. An observable ¢ = qS(a,-) on this space is a function of

the permutations 47,-, 1' 6 {1,. . . , 2"}.

% 31.txt
31

The energy of the system, when in state i, is deﬁned by the Hamiltonian

H07-‘) = - Z Ua(i)0s(k)

<j Ic>
where the sum runs over all neart neighbor pairs. In statistical mechanics we are often concerned

with the Gibbs measure of state i, deﬁned by
1r(a,-) = Z'1 exp{—[3H(a,~)} (5.1)
where Z ‘1 is the normalization constant, or partition function. For the Ising model, we put

Z = §:9XP{~ﬁH(<7:‘)}
i=1

so that 7r is a probability measure. Now, letting 1: denote the so called Boltzman constant, if a
classical mechanical system is in thermal equilibrium with its surroundings with absolute temper-
ature T, and is in state i with energy H (05), then the probability density in phase-space of the
point representing state i is given by (5.1) with [3 = (lcT)“. The central result of ergodic theory
implies that we can also interpret 1r(o;) as the proportion of time the system spends in state i. If

the system is observed at a random time, the expectation E,,¢ of any observable ¢ is thus

.31 ¢(0a) 9"l>{-ﬂH(0s‘)}

E” = 2?;.exp{—nH(a.-)}

(5.2)

Perhaps the number of sites n in our Ising model is so large that it is impractical or impossible to
evaluate (5.2). We might instead consider importance sampling and generate states with probability

density

exp{—aH<a.o}
2?;.exp{—zaH<a.->} (53)

Then «I: is itself an unbiased estimator of (5.2).

1r(0a') =

If evaluation of (5.2) is difficult, there is no reason to believe that evaluation of (5.3) is any

easier. However, Metropolis and his collaborators [9] contrived a method for producing an ergodic

% 32.txt
32

Markov chain with transition probability matrix K whose elements Ic(:::, y) satisfy

2«<z>k<x.y) = «<2»

I

By Deﬁnition 2.1.4 this means that the Markov chain has stationary distribution 7r. Since the
drain is ergodic, we know that it will eventually converge to the desired distribution. So, our main
problem — the rate at which such a Markov chain will converge — is clearly at issue in the application
of the Metropolis algorithm. Moreover, as we will see below, the Metropolis algorithm ensures that
the Markov chain has the desired stationary distribution by requiring that the chain satisfy the
stronger condition of reversibility; i.e. detailed balance. Therefore, Markov chains produced by the
Metropolis algorithm satisfy the assumptions of this paper, which fact conﬁrms that our theory

can be used to bound convergence rates of all such chains.

5.2 Description of the Metropolis Algorithm

The following explains how the Metropolis Algorithm is carried out. The exposition is
similar to that given in Hammersley and Handscomb’s book Monte Carlo Methods 
To begin, choose an arbitrary symmetric Markov chain; that is, a Markov chain whose

transition probability matrix P is symmetric. P is called the proposition matrix, and its elements,
P071"), Satisfy
pa, 1) 2 0. pm‘) = pm). 2,-pm‘) = 1 vi e S (5-4)

Using P, we will derive a new transition probability matrix K which satisﬁes

Z vr(z')k(='.:') = arm (5.5)

I

For 1' aé j deﬁne

kw) = p<-yum")/«<¢> it nu)/1r(='> <1 (5.6)

P(i,J') if 7r(J')/7r(i) Z1

% 33.txt
33

For 2' = j deﬁne

kw) = pm) (1—  p(-3;"), where J. = {j = 2‘ 7‘ an nu)/«(='> < 1}

Notice that 1r(i) > 0 implies k(i,j) _>_ 0 and

;k<«',j> = pow)  { (1 —  pm) +  +]§§p<«",:')
= P(is'5) + 2 P(i1.1') + Z P(iy.7') (5-7)
jel.» jug

Equation (5.7) shows that, for each i, 2, k(z', j) = 1, which fact conﬁrms that K is a stochastic

matrix.

Next we check that K satisﬁes the detailed balance condition. First suppose that 1r(z') =

1r(j). Then (5.4), (5.6), and symmetry of P imply
k(i,J') = p(i2.7') = p(jvi) = k(j1i)

and, since 1r(i) = 1r(j), the detailed balance condition, 1r(i)k(i,j) = 7r(j)k(i,j), clearly holds. Now

suppose that 1r(i) > 1r(j). Then (5.4) and (5.6) imply k(j,i) =p(j, 1') and
k(i,J') = P(iyJ')7r(J')/7r(i) = P(J3i)7r(J')/7r(i) = k(.1'» i)7r(J')/1r(i)

That is, 1r(i)lc(i,j) = 1r(j)k(i,j), as we set out to prove.
To complete the justification of the Metropolis algorithm, we note that the detailed balance
condition, 7r(i)k(i, j) = 1r(j)k(i, j), implies that 1r is indeed the stationary distribution for a Markov

chain with transition probability matrix K. To see this notice that

27r(i)k(i..7') = Zﬂijlkiiajl = 1r(J') Z/€(i,J‘) = 7r(J')

I i
We now summarize the tasks performed when implementing the Metropolis algorithm.

First, pick as a proposition matrix any symmetric stochastic matrix and denote it by P. Begin

% 34.txt
34

the simulation of the Markov chain in state i, and then take one step of the proposition Markov
chain to arrive in state j. That is, choose j according to the mass function p(z', -). Next, compute
1r(j)/1r(i). If 7r(j)/1r(i) 2 1, accept j as the new state. If1r(j)/1r(i') < 1, then with probability
1r(j)/7r(z') accept j as the new state; otherwise, with probability 1 — 1r(j)/1r(i), take i as the new
state. Performing each of these tasks produces one step of the Markov chain represented by the

transition probability matrix K.

5.3 The Ising Model

Returning to the Ising model considered in section 5.1, we consider how the Metropolis
algorithm is applied to such a mode]. Again, start the simulated chain in state X0 = 1' and let

X1 = j be a state chosen according to p(i, -), where p(i, j) = p(j,i). Next, compute

7"(‘7j)/7"(‘7i) = eXP{-ﬁlH(<7j) - H(0i)l}

Suppose the energy H (Uj) of the new state satisﬁes H (U,-) 3 H (05). Then 1r(a_,-)/1r(a,-) Z 1 and we

move to state j. On the other hand, if H(aj) > H(a;), then 1r(aj)/7r(a,-) < 1 and we take

j with probability e-M"

X1 (5.8)

i with probability 1 — e-W’
where AH E H (0,) — H (:75) is the change in energy from state j to state 1'.
There are many ways to choose a proposition matrix P. The simplest derives from the
so called Glauber dynamics, which proceeds as follows: choose one of the 11. sites at random with
probability 1/n — let .9 denote the chosen site — and change the position of this site; i.e., multiply

its value by -1. The resulting state j is the permutation of -1’s and +1’s given by

-0,-(k) if]: = .9
a,~(Ic)= (k=1,...,d)

a,-(Ic) if]: 95 s

% 35.txt
35

The procedure we employ below involves a slight variation: choose site .9 at random uniformly
from the 11 possible sites. However, instead of changing the value of the chosen site with absolute
certainty, as in Glauber dynamics, we “ﬂip the switch” with probability 1/2. Therefore, when k yé .9

we have 0',-(k) = a.~(k), and when k = 3,

—a,~(s) with probability 1/2
01(3) =

a,-(3) with probability 1/2
The advantage of this procedure is that the proposition matrix, before altering it with the Metropo-
lis algorithm, is a bit more interesting than that produced by traditional Glauber dynamics. For,
it has 1/2 along the main diagonal and, thus, is aperiodic and converges to a stationary distribu-
tion. Glauber dynamics has period 2, so its proposition matrix does not satisfy the hypotheses of

our convergence theorem (Theorem 2.1.2). Keep in mind, however, that any proposition matrix

modiﬁed by the Metropolis algorithm satisﬁes all of our hypotheses.

\section{Computations}
% Sec 5.4
\label{sec:computations}
5.4.1 Computer Programs

Constructing a computer program to simulate realizations of the Markov chain described
above (i.e. with transition matrix K) is straight forward, and we do so using Matlab and the
program ising.m which appears in the Appendix.

When performing simulations in the present context, there are a few important aspects
to consider. First, our program begins with a “hot start", which means that the initial state is
picked by assigning each site to :l:1 with probability 1/2. Perhaps we should instead have picked
our initial state from the stationary distribution. On the contrary, this would defeat the whole

purpose of our analysis. Recall that the method has been developed to deal with cases for which

% 36.txt
36

sampl from the stationary distribution are not quickly attainable. Furthermore, we are trying to
ﬁgure out how long it will take for observations from the simulated chain to represent samples from
the stationary distribution. Second, the method we have developed depends solely on covariances
of our observable which we estimate from the data. produced by the simulations. However, such
estimates require that the data come from the stationary distribution. Therefore, we must discard a
number of observations before using the data to estimate covariances. The number of observations
to discard depends on how long must we wait until we have data from the stationary distribution,
and we are back where we started — almost. When employing our procedure, we can discard a
conservative (very large) number of observations and perform our analysis, deriving a bound on
the convergence time. Then, in all future studies, we will know how much data should be discarded
before samples come (approximately) from the stationary distribution.

In considering what observable to use on the state space described above, perhaps the
most obvious is simply the number of nodes in the on position (i.e. the number of +l’s). Recalling
that 0, (k) = i1 denotes the position (on or off) of the kth node when the system is in state j, this

observable is deﬁned by,
«M = zxca.-ac) = +1). 1 = 1.---.ISl
I:

where X is the indicator function. The program ising.m simulates the Markov chain, computes the
values of this observable (as well as the number of 1’s squared) and writes it to a ﬁle called phi . dat.
The program then proceeds to compute the ﬁrst few Lanczos coefficients using covariances produced
by Matlab, so that we can check them against the rults we get from the 1anczos.c program,
which we now describe.

The lanczos .c program (listed in the Appendix along with its dependencies) implements
the recursive relations described in section 4.2 to compute the Lanczos coefﬁcients by the new

method. It accepts input from the user specifying any observable, any number of iterations, and any

% 37.txt
37

TABLE 1: ESTIMATES or /\,m(K) = 0.998746 USING ¢1

  
   
  
  
  
 

     
 

        
  
  

    
   
    
 

      
   
   

   

sim. # /32
1 0.995107 0.006960 0.995220 0.600243
2 0.995099 0.005891 0.994863 0.477393
3 0.994862 0.009671 0.994925 N/ A
4 0.995321 0.009319 0.995654 N/A
5 0.994787 0.004872 0.405446 0.994742

number of desired Lauczos coeﬁicients. That is, the observable could have come from a simulation
of any reversible Markov chain and not just our special Metropolis chain. The output of this
program is a T matrix containing the maximum number of Lauczos coeﬂicients (up to the number
requested by the user) before an approximate invariant subspace was reached. The eigenvalues of
the nonzero part of this matrix, in accordance with the foregoing theory, should well approximate

eigenvalues of the Markov chain’s stochastic matrix.

5.4.2 Results

Table 1 shows the results of 5 simulations each of 100,000 iterations (discarding the ﬁrst
5,000 observations) for the one dimensional Ising lattice with 10 nodes and [7 = 1. Displayed is
the estimate of the ﬁrst Lauczos coeﬂicient a1 (which is the eigenvalue estimate after one step; i.e.
).m,x(T1)), along with its error bound ﬁl. Appearing in the third column is the largest eigenvalue of
the 2 x 2 matrix T2, A0 (T2), and ﬁg appears in the fourth column when it is was computable. When
it was not computable, it was probably because an approximate invariant subspace was reached
at the ﬁrst step, so ﬁg involved expressions which were close to machine epsilon and, thus, could
not be computed accurately. Table 2 shows the same information when using a second observable,
¢2 E ¢§ (i.e. the number of +1’s squared).

The true value of the subdominant eigenvalue for this problem is /\max(K) = 0.998746,

and the next largest is A2(K) = 0.993303. These were computed directly from the transition matrix

% 38.txt
38

TABLE 2: ESTIMATES OF >.,,,,,.,,,(K) = 0.998746 USING z/>2

  
   
  
  
   
  

  
  
   
   

   
  
  
   
  

    
   
   
   

sim. # B2
1 0.994262 0.006142 0.994222 N / A
2 0.994333 0.002974 0.994332 N / A
3 0.994307 0.008892 0.994374 0.726320
4 0.994436 0.012884 0.994685 0.361404
5 0.993789 0.006909 0.993820 0.788710

using the Matlab program tpm.m listed in the Appendix. They should be very accurate, and it
takes the Matlab routine eig() just over 20 minutes of cpu time on a Sun Ultra to ﬁnd all the
eigenvalues of K.

As shown by Theorem 4.1.1, the [Ts provide conservative error bounds on the eigenvalue
estimates from the previous Lanczos step. Unfortunately, for this example, ,6 appears to be too
conservative as it does not even allow us to bound our estimates away from 1. Furthermore, it
seems that the estimates generated by the method above fall systematically below the true value of
the subdominant eigenvalue. In every simulation, an approximate invariant subspace (to machine
tolerance) was reached after computing at most 2 pairs of Lanczos coefficients. For ¢1 we see that
it was reached after computing only one pair on simulations 3 and 4, similarly for ¢2 on simulations
1 and 2. These observations indicate that the chosen observable is close to the slowest mode (or
eigenfunction) of the process. That is, we should observe fast convergence on an approximate
invariant space. However, the space found might contain only the second slowest mode of the
process and, in that case, our eigenvalue estimates would be closer to the third largest eigenvalue,
instead of the second largest as desired.‘

The matrix T was produced by the program lanczos . c and its eigenvalues were computed
by Matlab, both operations taking a few seconds. Granted, comparing a few seconds to the 20

minutes it takes Matlab is not justiﬁed since a simple call to the routine eig() is far from the

 

‘Recall that we explained above why we will never converge to the eigenspace corresponding to the largest eigen-
value (which is always 1). That would require a (nearly) constant observable function.

% 39.txt
39

most eﬂicient traditional method for computing only a few eigenvalues of K. However, recall that
the primary motivation for the new method are those examples where the matrix K is so large
that we can’t store even a single vector in fast memory. Once we start swapping data to and from
cheap memory, the time required by traditional algorithms can become years, even lifetimes. Such
examples are not exceptional. Consider, for instance, the 1000 node problem which produces a.

2“’°° x 21°°° transition matrix.

% 40.txt
40

